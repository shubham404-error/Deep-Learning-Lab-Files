{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Building an ***artificial neural network*** on the MNIST dataset using TensorFlow and Keras in Python\n",
        "\n",
        ">In this code, we first load the MNIST dataset using mnist.load_data(). Then we normalize the pixel values to be between 0 and 1.\n",
        "\n",
        ">Next, we define the neural network architecture using keras.Sequential(). The first layer is a layers.Flatten() layer, which flattens the input images to a 1D array. The next layer is a layers.Dense() layer with 128 units and a ReLU activation function. Finally, we have another layers.Dense() layer with 10 units, one for each possible digit.\n",
        "\n",
        ">We then compile the model using model.compile(). We use the Adam optimizer, and the loss function is tf.keras.losses.SparseCategoricalCrossentropy(), which is appropriate for multi-class classification problems like MNIST. We also track the accuracy metric during training.\n",
        "\n",
        ">We train the model on the training data using model.fit(). We run 10 epochs of training in this example.\n",
        "\n",
        ">Finally, we evaluate the model on the test data using model.evaluate(), and print the test accuracy."
      ],
      "metadata": {
        "id": "O7no9LRQw_5o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qH6kT9WRu7LY",
        "outputId": "a3bc0987-1b82-43f9-a579-2eaa00c9dec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2566 - accuracy: 0.9257\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1113 - accuracy: 0.9663\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0762 - accuracy: 0.9770\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0575 - accuracy: 0.9826\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0438 - accuracy: 0.9872\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0350 - accuracy: 0.9888\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0270 - accuracy: 0.9918\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0231 - accuracy: 0.9928\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0185 - accuracy: 0.9943\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0158 - accuracy: 0.9951\n",
            "313/313 - 0s - loss: 0.0682 - accuracy: 0.9823 - 405ms/epoch - 1ms/step\n",
            "Test accuracy: 0.9822999835014343\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Define the model architecture\n",
        "model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    }
  ]
}