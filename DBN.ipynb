{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c_f3UmQ0nSv"
   },
   "source": [
    "# Deep Belief Networks \n",
    "Here, the DBN class initializes the DBN with the input dimensions, hidden layer dimensions, and output dimension. The RBM layers and batch normalization layers are added to the network in a loop, with the input layer defined separately. The output layer is also defined separately. The network is compiled with the Adam optimizer and cross-entropy loss. The pretrain function trains the RBMs layer-by-layer using unsupervised learning. The train function fine-tunes the network with supervised learning. The evaluate function returns the loss and accuracy on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9pUHCfDoC-F"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class DBN():\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.rbm_layers = []\n",
    "        self.bn_layers = []\n",
    "        self.num_layers = len(hidden_dims)\n",
    "        \n",
    "        for i, dim in enumerate(hidden_dims):\n",
    "            if i == 0:\n",
    "                rbm_layer = Dense(dim, activation='sigmoid', input_dim=input_dim)\n",
    "            else:\n",
    "                rbm_layer = Dense(dim, activation='sigmoid')\n",
    "            self.rbm_layers.append(rbm_layer)\n",
    "            bn_layer = tf.keras.layers.BatchNormalization()\n",
    "            self.bn_layers.append(bn_layer)\n",
    "            \n",
    "        self.output_layer = Dense(output_dim, activation='softmax')\n",
    "        \n",
    "        self.model = Sequential(self.rbm_layers + self.bn_layers + [self.output_layer])\n",
    "        \n",
    "        self.model.compile(optimizer=Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def pretrain(self, X, batch_size=32, epochs=100):\n",
    "        for i in range(self.num_layers):\n",
    "            rbm = self.rbm_layers[i]\n",
    "            rbm.trainable = True\n",
    "            bn = self.bn_layers[i]\n",
    "            bn.trainable = False\n",
    "            \n",
    "            rbm_model = Sequential([rbm])\n",
    "            rbm_model.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy')\n",
    "            rbm_model.fit(X, X, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "            \n",
    "            rbm.trainable = False\n",
    "            bn.trainable = True\n",
    "            \n",
    "            X = rbm.predict(X)\n",
    "            \n",
    "    def train(self, X, y, batch_size=32, epochs=100):\n",
    "        self.model.fit(X, y, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "        \n",
    "    def evaluate(self, X, y, batch_size=32):\n",
    "        return self.model.evaluate(X, y, batch_size=batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
